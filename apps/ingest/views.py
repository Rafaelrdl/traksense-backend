import logging
from datetime import datetime, timezone as dt_timezone

from django.conf import settings
from django.db import connection, transaction
from django.utils import timezone as dj_timezone
from django.utils.decorators import method_decorator
from django.views.decorators.csrf import csrf_exempt
from rest_framework import status
from rest_framework.response import Response
from rest_framework.views import APIView

from apps.tenants.models import Tenant
from .models import Telemetry, Reading
from .parsers import parser_manager


logger = logging.getLogger(__name__)


@method_decorator(csrf_exempt, name='dispatch')
class IngestView(APIView):
    """
    Endpoint to receive telemetry data from EMQX Rule Engine.
    
    This endpoint bypasses multi-tenant middleware by manually switching
    to the tenant schema based on x-tenant header.
    
    Expected payload from EMQX:
    {
        "client_id": "device-001",
        "topic": "tenants/umc/devices/001/sensors/temperature",
        "payload": {"value": 23.5, "unit": "celsius"},
        "ts": 1697572800000  // Unix timestamp in milliseconds
    }
    
    Headers expected:
    - x-tenant: tenant slug (e.g., "umc")
    - x-device-token: HMAC signature or device API token (for authentication)
    - content-type: application/json
    
    Security:
    - Validates x-device-token against INGESTION_SECRET or registered device tokens
    - Validates tenant slug from topic matches x-tenant header
    - Rejects requests with invalid authentication
    """
    
    # Disable DRF authentication (using custom device token auth)
    authentication_classes = []
    permission_classes = []
    
    def post(self, request, *args, **kwargs):
        """
        Process incoming telemetry data from EMQX.
        
        üîí SECURITY: Requires valid device authentication via:
        - x-device-token header with HMAC signature OR
        - Registered device API token
        """
        # üîí SECURITY: Validate device authentication FIRST
        device_token = request.headers.get('x-device-token')
        if not device_token:
            logger.warning("Missing x-device-token header in ingest request")
            return Response(
                {"error": "Missing x-device-token header"},
                status=status.HTTP_401_UNAUTHORIZED
            )
        
        # Validate device token (HMAC or registered token)
        from django.conf import settings
        import hmac
        import hashlib
        
        # SECURITY: INGESTION_SECRET is REQUIRED
        ingestion_secret = getattr(settings, 'INGESTION_SECRET', None)
        if not ingestion_secret:
            logger.error("üö® SECURITY: INGESTION_SECRET not configured - rejecting ingestion")
            return Response(
                {"error": "Server configuration error - authentication unavailable"},
                status=status.HTTP_401_UNAUTHORIZED
            )
        
        # Validate HMAC signature
        expected_token = hmac.new(
            ingestion_secret.encode('utf-8'),
            request.body,
            hashlib.sha256
        ).hexdigest()
        
        if not hmac.compare_digest(device_token, expected_token):
            logger.error(f"üö® SECURITY: Invalid device token from {request.META.get('REMOTE_ADDR')}")
            return Response(
                {"error": "Invalid device token"},
                status=status.HTTP_401_UNAUTHORIZED
            )
        
        # Continue with tenant validation and processing...
        # üîß Only log verbose details in DEBUG mode
        if settings.DEBUG:
            logger.info("=" * 60)
            logger.info("üîµ INGEST POST INICIADO")
            logger.info(f"Headers: {dict(request.headers)}")
            logger.info(f"Content-Type: {request.content_type}")
            logger.info(f"üìè Body tamanho: {len(request.body)} bytes")
            logger.info(f"Body COMPLETO: {request.body.decode('utf-8')}")
            logger.info("=" * 60)
        
        # Extract tenant from header
        tenant_slug = request.headers.get('x-tenant')
        if not tenant_slug:
            logger.warning("Missing x-tenant header in ingest request")
            return Response(
                {"error": "Missing x-tenant header"},
                status=status.HTTP_400_BAD_REQUEST
            )

        # Parse and validate payload BEFORE accessing database
        try:
            # Validate payload structure
            if settings.DEBUG:
                logger.info("üîç Parseando JSON manualmente do request.body...")
            import json
            try:
                raw_body = request.body.decode('utf-8')
                if settings.DEBUG:
                    logger.info(f"üìè Body completo ({len(raw_body)} chars): {raw_body}")
                data = json.loads(raw_body)
                if settings.DEBUG:
                    logger.info(f"‚úÖ JSON parseado com sucesso, tipo: {type(data)}")
            except json.JSONDecodeError as e_json:
                logger.error(f"‚ùå Erro ao parsear JSON: {e_json}", exc_info=True)
                logger.error(f"JSON problem√°tico: {raw_body}")
                return Response(
                    {"error": f"Erro ao parsear JSON: {str(e_json)}"},
                    status=status.HTTP_400_BAD_REQUEST
                )
            except Exception as e_data:
                logger.error(f"‚ùå Erro inesperado: {e_data}", exc_info=True)
                return Response(
                    {"error": f"Erro ao processar request: {str(e_data)}"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            if settings.DEBUG:
                logger.info(f"üì• Ingest received data: {data}")

            if not isinstance(data, dict):
                logger.warning(f"Invalid payload type: {type(data)}")
                return Response(
                    {"error": "Payload must be JSON object"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            topic = data.get('topic')
            if not topic:
                logger.warning("Missing required field: topic")
                return Response(
                    {"error": "Missing required field: topic"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # üîí SECURITY: Validate tenant from topic matches x-tenant header
            # This validation happens BEFORE database access to prevent enumeration attacks
            # Topic format: tenants/{slug}/sites/{site}/assets/{tag}/telemetry
            topic_parts = topic.split('/')
            if len(topic_parts) < 2 or topic_parts[0] != 'tenants':
                logger.warning(f"Invalid topic format: {topic}")
                return Response(
                    {"error": "Invalid topic format"},
                    status=status.HTTP_400_BAD_REQUEST
                )
            
            topic_tenant_slug = topic_parts[1]
            if topic_tenant_slug != tenant_slug:
                logger.error(
                    f"üö® SECURITY VIOLATION: Tenant mismatch! "
                    f"Header: {tenant_slug}, Topic: {topic_tenant_slug}, "
                    f"Client: {data.get('client_id')}, Full Topic: {topic}"
                )
                return Response(
                    {"error": "Tenant validation failed"},
                    status=status.HTTP_403_FORBIDDEN
                )

        except Exception as e:
            logger.error(f"‚ùå Erro ao validar payload: {e}", exc_info=True)
            return Response(
                {"error": "Invalid request"},
                status=status.HTTP_400_BAD_REQUEST
            )

        # NOW we can safely access the database with validated tenant
        try:
            connection.set_schema_to_public()
            tenant = Tenant.objects.get(slug=tenant_slug)
            connection.set_tenant(tenant)
        except Tenant.DoesNotExist:
            logger.warning(f"Tenant not found: {tenant_slug}")
            return Response(
                {"error": "Internal server error"},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

        def ensure_aware_timestamp(value, fallback):
            """Converte timestamps em datetime timezone-aware."""
            if value is None:
                return fallback
            if isinstance(value, str):
                try:
                    value = datetime.fromisoformat(value.replace('Z', '+00:00'))
                except ValueError:
                    logger.warning(f"‚ö†Ô∏è Timestamp inv√°lido recebido: {value}")
                    return fallback
            if isinstance(value, (int, float)):
                try:
                    # Assume valor em segundos; se vier em milissegundos, converter
                    if abs(value) > 1e12:
                        value = value / 1000.0
                    value = datetime.fromtimestamp(value, tz=dt_timezone.utc)
                except (ValueError, OSError, OverflowError) as exc:
                    logger.warning(f"‚ö†Ô∏è Falha ao converter timestamp num√©rico {value}: {exc}")
                    return fallback
            if isinstance(value, datetime):
                if dj_timezone.is_naive(value):
                    return dj_timezone.make_aware(value, dt_timezone.utc)
                return value
            return fallback

        # Continue processing with validated data and connected tenant
        try:
            client_id = data.get('client_id')
            payload = data.get('payload')
            ts = data.get('ts')

            if not all([payload, ts]):
                missing = [f for f in ['payload', 'ts'] if not data.get(f)]
                logger.warning(f"Missing required fields: {missing}")
                return Response(
                    {"error": f"Missing required fields: {', '.join(missing)}"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            try:
                ingest_timestamp = datetime.fromtimestamp(ts / 1000.0, tz=dt_timezone.utc)
            except (ValueError, TypeError, OSError, OverflowError) as e:
                logger.warning(f"Invalid timestamp: {ts} - {e}")
                return Response(
                    {"error": "Invalid timestamp format"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            if isinstance(payload, str):
                import json
                try:
                    payload = json.loads(payload)
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse payload JSON: {e}")
                    return Response(
                        {"error": "Invalid JSON in payload"},
                        status=status.HTTP_400_BAD_REQUEST
                    )

            if settings.DEBUG:
                logger.info(f"üîç Tentando encontrar parser para topic: {topic}")
                logger.info(f"üîç Tipo do payload: {type(payload)}")
                logger.info(f"üîç Payload preview: {str(payload)[:200]}")
            
            # IMPORTANTE: Passar o payload interno, n√£o o data completo!
            parser = parser_manager.get_parser(payload, topic)

            if not parser:
                logger.warning(f"‚ö†Ô∏è Nenhum parser encontrado para o payload. Topic: {topic}")
                if settings.DEBUG:
                    logger.warning(f"‚ö†Ô∏è Payload recebido: {payload}")
                    logger.warning(f"‚ö†Ô∏è Parsers dispon√≠veis: {[p.__class__.__name__ for p in parser_manager._parsers]}")
                return Response(
                    {"error": "Formato de payload n√£o reconhecido"},
                    status=status.HTTP_400_BAD_REQUEST
                )

            try:
                # IMPORTANTE: Passar o payload interno, n√£o o data completo!
                parsed_data = parser.parse(payload, topic)
                if settings.DEBUG:
                    logger.info(f"‚úÖ Payload parseado com sucesso usando {parser.__class__.__name__}")
                    logger.info(f"üìä Device: {parsed_data['device_id']}, Sensors: {len(parsed_data['sensors'])}")
            except Exception as e:
                logger.error(f"‚ùå Erro ao parsear payload: {e}", exc_info=True)
                return Response(
                    {"error": f"Erro ao processar payload: {str(e)}"},
                    status=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

            device_id = parsed_data['device_id']
            sensors = parsed_data['sensors']
            metadata = parsed_data.get('metadata', {})
            base_timestamp = ensure_aware_timestamp(parsed_data.get('timestamp'), ingest_timestamp)
            parsed_data['timestamp'] = base_timestamp

            try:
                with transaction.atomic():
                    telemetry = Telemetry.objects.create(
                        device_id=device_id,
                        topic=topic,
                        payload=payload,
                        timestamp=ingest_timestamp
                    )

                    # Auto linking - extract hierarchy from MQTT topic
                    site_name, asset_tag = self._extract_site_and_asset_from_topic(topic)
                    
                    # Extract tenant from topic (tenants/{tenant}/...)
                    tenant_name = None
                    topic_parts = topic.split('/')
                    if 'tenants' in topic_parts:
                        tenant_idx = topic_parts.index('tenants')
                        if tenant_idx + 1 < len(topic_parts):
                            tenant_name = topic_parts[tenant_idx + 1]

                    if asset_tag:
                        logger.info(f"üîó Asset tag extra√≠do do t√≥pico: {asset_tag}")
                        if site_name:
                            logger.info(f"üìç Site extra√≠do do t√≥pico: {site_name}")
                        if tenant_name:
                            logger.info(f"üè¢ Tenant extra√≠do do t√≥pico: {tenant_name}")

                        asset = self._auto_create_and_link_asset(
                            site_name=site_name,
                            asset_tag=asset_tag,
                            device_id=device_id,
                            parsed_data=parsed_data
                        )

                        if asset:
                            logger.info(f"‚úÖ Asset {asset_tag} processado no site {asset.site.name}")
                        else:
                            logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel processar asset {asset_tag}")
                    else:
                        logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel extrair asset_tag do t√≥pico: {topic}")

                    readings_to_create = []
                    duplicates_skipped = 0

                    for sensor in sensors:
                        if not isinstance(sensor, dict):
                            continue

                        sensor_id = sensor.get('sensor_id')
                        value = sensor.get('value')

                        if not sensor_id or value is None:
                            continue

                        labels = sensor.get('labels', {})
                        if not isinstance(labels, dict):
                            labels = {}

                        reading_timestamp = ensure_aware_timestamp(sensor.get('timestamp'), base_timestamp)

                        # üîß PERFORMANCE FIX: Remove redundant .exists() check
                        # bulk_create with ignore_conflicts=True already handles duplicates
                        # This .exists() causes N database roundtrips for each sensor
                        
                        readings_to_create.append(
                            Reading(
                                device_id=device_id,
                                sensor_id=sensor_id,
                                value=float(value),
                                labels=labels,
                                ts=reading_timestamp,
                                # MQTT Topic Hierarchy (source of truth)
                                asset_tag=asset_tag,
                                tenant=tenant_name,
                                site=site_name
                            )
                        )

                    if readings_to_create:
                        # üîí SECURITY FIX #4: Use ignore_conflicts to prevent race condition
                        # Concurrent ingestions can violate unique constraint (device_id, sensor_id, ts)
                        # Instead of dropping entire batch on IntegrityError, silently skip duplicates
                        created_count = Reading.objects.bulk_create(
                            readings_to_create, 
                            ignore_conflicts=True
                        )
                        # Note: ignore_conflicts returns empty list in Django, so we can't count actual inserts
                        # But we can report the attempt count
                        readings_created = len(readings_to_create)
                        
                        # Atualizar status do device para ONLINE e last_seen
                        try:
                            from apps.assets.models import Device
                            Device.objects.filter(mqtt_client_id=device_id).update(
                                status='ONLINE',
                                last_seen=dj_timezone.now()
                            )
                            logger.info(f"‚úÖ Device {device_id} marcado como ONLINE")
                        except Exception as e_device:
                            logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel atualizar status do device: {e_device}")

                    readings_created = len(readings_to_create)

                logger.info(
                    f"‚úÖ Telemetry saved: tenant={tenant_slug}, "
                    f"device={device_id}, topic={topic}, format={metadata.get('format', 'unknown')}"
                )
                logger.info(
                    f"üìä Created {readings_created} sensor readings (duplicados ignorados: {duplicates_skipped})"
                )

                response_data = {
                    "status": "accepted",
                    "id": telemetry.id,
                    "device_id": telemetry.device_id,
                    "timestamp": telemetry.timestamp.isoformat(),
                    "sensors_saved": readings_created,
                    "duplicates_skipped": duplicates_skipped,
                    "format": metadata.get('format', 'unknown')
                }

                if metadata.get('gateway_id'):
                    response_data['gateway_id'] = metadata['gateway_id']
                if metadata.get('model'):
                    response_data['model'] = metadata['model']

                return Response(response_data, status=status.HTTP_202_ACCEPTED)

            except Exception as e:
                logger.error(f"Failed to save telemetry: {e}", exc_info=True)
                return Response(
                    {"error": "Failed to save telemetry"},
                    status=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

        finally:
            connection.set_schema_to_public()
    
    def _extract_site_and_asset_from_topic(self, topic):
        """
        Extrai site_name e asset_tag do t√≥pico MQTT.
        
        Padr√µes suportados:
        - tenants/{tenant}/sites/{site_name}/assets/{asset_tag}/telemetry (NOVO - com site)
        - tenants/{tenant}/assets/{asset_tag}/telemetry (legado - sem site)
        
        Returns:
            tuple: (site_name, asset_tag) ou (None, None)
        """
        from urllib.parse import unquote
        
        parts = topic.split('/')
        site_name = None
        asset_tag = None
        
        try:
            # Novo padr√£o com site
            if 'sites' in parts and 'assets' in parts:
                site_idx = parts.index('sites')
                asset_idx = parts.index('assets')
                
                if site_idx + 1 < len(parts):
                    site_name = parts[site_idx + 1]
                    # Decodificar URL encoding se necess√°rio
                    site_name = unquote(site_name)
                
                if asset_idx + 1 < len(parts):
                    asset_tag = parts[asset_idx + 1]
                    
                logger.info(f"‚úÖ Extra√≠do do t√≥pico - Site: {site_name}, Asset: {asset_tag}")
                
            # Padr√£o legado sem site (mant√©m compatibilidade)
            elif 'assets' in parts:
                asset_idx = parts.index('assets')
                if asset_idx + 1 < len(parts):
                    asset_tag = parts[asset_idx + 1]
                    logger.info(f"‚úÖ Asset extra√≠do (sem site): {asset_tag}")
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair informa√ß√µes do t√≥pico: {e}")
            
        return site_name, asset_tag
    
    def _detect_asset_type(self, asset_tag):
        """
        Detecta o tipo de asset baseado no tag.
        """
        tag_upper = asset_tag.upper()
        
        if 'CHILLER' in tag_upper or 'CH-' in tag_upper:
            return 'CHILLER'
        elif 'AHU' in tag_upper:
            return 'AHU'
        elif 'VRF' in tag_upper:
            return 'VRF'
        elif 'FCU' in tag_upper:
            return 'FCU'
        elif 'SPLIT' in tag_upper:
            return 'SPLIT'
        elif 'RTU' in tag_upper:
            return 'RTU'
        elif 'COOLING' in tag_upper or 'TOWER' in tag_upper:
            return 'COOLING_TOWER'
        else:
            return 'OTHER'
    
    def _auto_create_and_link_asset(self, site_name, asset_tag, device_id, parsed_data):
        """
        Cria ou atualiza automaticamente asset e vincula device/sensores.
        
        Fluxo:
        1. Se site_name fornecido, busca ou cria o site
        2. Busca ou cria o asset no site correto
        3. Busca ou cria o device e vincula ao asset
        4. Vincula sensores ao device
        
        Args:
            site_name: Nome do site (pode ser None)
            asset_tag: Tag do asset
            device_id: ID MQTT do device
            parsed_data: Dados parseados do payload (incluindo metadata e sensors)
        
        Returns:
            Asset object ou None
        """
        try:
            from apps.assets.models import Site, Asset, Device, Sensor
            from django.utils import timezone
            
            # 1. Determinar o site
            site = None
            if site_name:
                site = Site.objects.filter(name=site_name, is_active=True).first()
                if site:
                    logger.info(f"üìç Site encontrado: {site.name}")
                else:
                    logger.warning(f"‚ö†Ô∏è Site '{site_name}' n√£o encontrado. Ignorando auto-cria√ß√£o.")
                    return None
            else:
                # üîí SECURITY FIX #5: Reject missing site metadata instead of guessing
                # Previously used .first() which silently attached devices to arbitrary sites,
                # corrupting the asset hierarchy and breaking tenant isolation
                logger.error(
                    f"‚ùå Missing site metadata in topic for asset {asset_tag}. "
                    f"Topic MUST encode site: tenants/{{tenant}}/sites/{{site}}/assets/{{asset}}/telemetry"
                )
                return None
            
            if not site:
                logger.error("‚ùå Nenhum site dispon√≠vel para vincular o asset")
                return None
            
            # 2. Buscar ou criar o asset
            asset, asset_created = Asset.objects.get_or_create(
                tag=asset_tag,
                defaults={
                    'name': f'{asset_tag}',
                    'site': site,
                    'asset_type': self._detect_asset_type(asset_tag),
                    'status': 'OPERATIONAL',
                    'health_score': 100,
                    'is_active': True
                }
            )
            
            if asset_created:
                logger.info(f"‚ú® Asset criado automaticamente: {asset.tag} no site {site.name}")
            else:
                # Atualizar site do asset se mudou
                if asset.site != site:
                    old_site = asset.site.name
                    asset.site = site
                    asset.save(update_fields=['site', 'updated_at'])
                    logger.info(f"üîÑ Asset {asset_tag} movido de {old_site} para {site.name}")
                else:
                    logger.debug(f"‚úÖ Asset {asset_tag} j√° existe no site {site.name}")
            
            # 3. Buscar ou criar o device e vincular ao asset
            metadata = parsed_data.get('metadata', {})
            device, device_created = Device.objects.get_or_create(
                mqtt_client_id=device_id,
                defaults={
                    'asset': asset,
                    'name': f'Gateway {asset_tag}',
                    'serial_number': device_id,
                    'device_type': 'GATEWAY',
                    'firmware_version': metadata.get('model', 'unknown'),
                    'status': 'OFFLINE',
                    'is_active': True,
                    'last_seen': timezone.now()
                }
            )
            
            if device_created:
                logger.info(f"‚ú® Device criado e vinculado ao asset {asset_tag}")
            else:
                # Atualizar asset do device se mudou
                if device.asset != asset:
                    old_asset = device.asset.tag if device.asset else 'N/A'
                    device.asset = asset
                    device.last_seen = timezone.now()
                    device.save(update_fields=['asset', 'last_seen', 'updated_at'])
                    logger.info(f"üîÑ Device {device_id} movido de {old_asset} para {asset_tag}")
                else:
                    # Apenas atualizar last_seen
                    device.last_seen = timezone.now()
                    device.save(update_fields=['last_seen'])
            
            # 4. Processar sensores do payload
            if 'sensors' in parsed_data:
                for sensor_data in parsed_data['sensors']:
                    sensor_id = sensor_data.get('sensor_id')
                    if not sensor_id:
                        continue
                    
                    labels = sensor_data.get('labels', {})
                    sensor_type = labels.get('type', 'unknown')
                    unit = labels.get('unit', '')
                    
                    # Buscar ou criar sensor
                    sensor, sensor_created = Sensor.objects.get_or_create(
                        tag=sensor_id,
                        device=device,
                        defaults={
                            'metric_type': self._map_sensor_type_to_metric(sensor_type),
                            'unit': unit,
                            'is_online': True,
                            'is_active': True
                        }
                    )
                    
                    if sensor_created:
                        logger.info(f"‚ú® Sensor {sensor_id} criado e vinculado ao device {device_id}")
                    
                    # Atualizar √∫ltimo valor do sensor
                    value = sensor_data.get('value')
                    if value is not None:
                        sensor.last_value = value
                        sensor.last_reading_at = timezone.now()
                        sensor.is_online = True
                        sensor.save(update_fields=['last_value', 'last_reading_at', 'is_online', 'updated_at'])
            
            return asset
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao criar/vincular asset: {e}", exc_info=True)
            return None
    
    def _map_sensor_type_to_metric(self, sensor_type):
        """
        Mapeia sensor_type do parser para metric_type do model Sensor.
        """
        mapping = {
            'temperature': 'temperature',
            'humidity': 'humidity',
            'pressure': 'pressure',
            'counter': 'counter',
            'signal_strength': 'signal',
            'battery': 'voltage',
            'door_state': 'status',
            'unknown': 'other'
        }
        return mapping.get(sensor_type, 'other')
    
    def _extract_asset_tag_from_topic(self, topic):
        """
        Extrai o asset_tag do t√≥pico MQTT.
        
        Padr√µes suportados:
        - tenants/{tenant}/assets/{asset_tag}/telemetry
        - tenants/{tenant}/devices/{device_id}/assets/{asset_tag}
        - {asset_tag}/telemetry
        
        Args:
            topic (str): T√≥pico MQTT completo
        
        Returns:
            str or None: Asset tag extra√≠do ou None se n√£o encontrado
        """
        parts = topic.split('/')
        
        # Padr√£o 1: tenants/{tenant}/assets/{asset_tag}/telemetry
        if 'assets' in parts:
            try:
                asset_idx = parts.index('assets')
                if asset_idx + 1 < len(parts):
                    asset_tag = parts[asset_idx + 1]
                    logger.info(f"‚úÖ Asset tag extra√≠do (padr√£o 1): {asset_tag}")
                    return asset_tag
            except (ValueError, IndexError):
                pass
        
        # Padr√£o 2: {asset_tag}/telemetry (tag diretamente)
        # Valida se o primeiro componente parece uma tag de ativo (ex: CH-001, AHU-001)
        if len(parts) >= 1:
            potential_tag = parts[0]
            if '-' in potential_tag and len(potential_tag) <= 50:
                logger.info(f"‚úÖ Asset tag extra√≠do (padr√£o 2): {potential_tag}")
                return potential_tag
        
        return None
    
    def _auto_link_sensors_to_asset(self, asset_tag, payload, device_id):
        """
        Vincula automaticamente sensores ao ativo baseado no t√≥pico.
        
        Fluxo:
        1. Busca o Asset pelo tag
        2. Para cada sensor no payload:
           a. Busca ou cria um Device padr√£o para o Asset
           b. Busca o Sensor pelo sensor_id
           c. Se o Sensor existe mas n√£o est√° vinculado corretamente, atualiza
           d. Se o Sensor n√£o existe, apenas registra no log (ser√° criado manualmente)
        
        Args:
            asset_tag (str): Tag do ativo (ex: CH-001)
            payload (dict): Payload MQTT com lista de sensores
            device_id (str): ID do dispositivo MQTT
        """
        try:
            from apps.assets.models import Asset, Device, Sensor
            
            # Busca o ativo pelo tag
            try:
                asset = Asset.objects.get(tag=asset_tag, is_active=True)
                logger.info(f"üéØ Asset encontrado: {asset.tag} - {asset.name}")
            except Asset.DoesNotExist:
                logger.warning(f"‚ö†Ô∏è Asset n√£o encontrado: {asset_tag}")
                return
            
            # Busca ou cria um Device padr√£o para o ativo
            # Usa o mqtt_client_id como refer√™ncia
            device, device_created = Device.objects.get_or_create(
                mqtt_client_id=device_id,
                defaults={
                    'asset': asset,
                    'name': f'Gateway {asset_tag}',
                    'serial_number': f'SN-{device_id}',
                    'device_type': 'GATEWAY',
                    'status': 'ONLINE'
                }
            )
            
            if device_created:
                logger.info(f"‚ú® Device criado automaticamente: {device.name} para asset {asset_tag}")
            else:
                # Se o device j√° existe mas est√° em outro asset, atualiza
                if device.asset_id != asset.id:
                    logger.info(f"üîÑ Device {device.name} movido de {device.asset.tag} para {asset_tag}")
                    device.asset = asset
                    device.save(update_fields=['asset', 'updated_at'])
            
            # Processa cada sensor no payload
            sensors = payload.get('sensors', []) if isinstance(payload, dict) else []
            
            for sensor_data in sensors:
                if not isinstance(sensor_data, dict):
                    continue
                
                sensor_id = sensor_data.get('sensor_id')
                if not sensor_id:
                    continue
                
                try:
                    # Busca o sensor pelo tag (sensor_id)
                    sensor = Sensor.objects.filter(tag=sensor_id, is_active=True).first()
                    
                    if sensor:
                        # Se o sensor existe mas est√° em device diferente, atualiza
                        if sensor.device_id != device.id:
                            old_asset = sensor.device.asset.tag if sensor.device else 'N/A'
                            logger.info(f"üîÑ Sensor {sensor_id} movido de {old_asset} para {asset_tag}")
                            sensor.device = device
                            sensor.save(update_fields=['device', 'updated_at'])
                        else:
                            logger.debug(f"‚úÖ Sensor {sensor_id} j√° vinculado ao asset {asset_tag}")
                    else:
                        # ‚ú® AUTO-REGISTRO: Cria o sensor automaticamente
                        sensor = self._auto_create_sensor(
                            device=device,
                            sensor_id=sensor_id,
                            sensor_data=sensor_data
                        )
                        if sensor:
                            logger.info(
                                f"‚ú® Sensor criado automaticamente: {sensor_id} ‚Üí "
                                f"{sensor.get_metric_type_display()} ({sensor.unit})"
                            )
                
                except Exception as e:
                    logger.error(f"‚ùå Erro ao processar sensor {sensor_id}: {e}", exc_info=True)
        
        except Exception as e:
            logger.error(f"‚ùå Erro no auto-link de sensores ao asset {asset_tag}: {e}", exc_info=True)
    
    def _auto_create_sensor(self, device, sensor_id, sensor_data):
        """
        Cria automaticamente um sensor baseado nos dados do payload.
        
        Mapeia os tipos e unidades do payload para os tipos suportados
        pelo modelo Sensor.
        
        Args:
            device: Objeto Device ao qual vincular o sensor
            sensor_id: Tag/ID do sensor
            sensor_data: Dados do sensor do payload com 'labels', 'value', etc.
        
        Returns:
            Sensor: Objeto Sensor criado ou None se falhar
        """
        try:
            from apps.assets.models import Sensor
            
            labels = sensor_data.get('labels', {})
            unit = labels.get('unit', 'N/A')
            sensor_type = labels.get('type', 'unknown')
            
            # Mapeamento de tipos do payload para SENSOR_TYPE_CHOICES
            type_mapping = {
                'temperature': 'temp_supply',
                'humidity': 'humidity',
                'pressure': 'pressure_suction',
                'signal_strength': 'maintenance',  # RSSI ‚Üí manuten√ß√£o/status
                'power': 'power_kw',
                'energy': 'energy_kwh',
                'voltage': 'voltage',
                'current': 'current',
                'ambient': 'temp_external',
                'binary_counter': 'maintenance',
                'counter': 'maintenance',
                'unknown': 'maintenance',
            }
            
            # Determina o metric_type baseado no tipo do sensor
            metric_type = type_mapping.get(sensor_type, 'maintenance')
            
            # Se temos informa√ß√µes mais espec√≠ficas nos labels, usa elas
            if 'metric_type' in labels:
                metric_type = labels['metric_type']
            
            # Cria o sensor
            sensor = Sensor.objects.create(
                tag=sensor_id,
                device=device,
                metric_type=metric_type,
                unit=unit,
                thresholds={},  # Pode ser configurado posteriormente
                is_active=True
            )
            
            logger.info(
                f"‚úÖ Sensor auto-criado: {sensor_id} | "
                f"Type: {metric_type} | Unit: {unit} | Device: {device.mqtt_client_id}"
            )
            
            return sensor
            
        except Exception as e:
            logger.error(
                f"‚ùå Erro ao criar sensor automaticamente {sensor_id}: {e}",
                exc_info=True
            )
            return None
